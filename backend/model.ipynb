{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f0f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265eab5",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5078552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_key(lat, lon):\n",
    "    return (round(lat / GRID_RESOLUTION), round(lon / GRID_RESOLUTION))\n",
    "\n",
    "def sample_line_count_estimate(tar_path, target_csv=\"observations\", sample_bytes=100_000_000):\n",
    "    \"\"\"\n",
    "    Estimate total line count by sampling the first few MB of the file inside the tar.gz.\n",
    "    \"\"\"\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        for member in tar:\n",
    "            if member.name.endswith(\".csv\") and target_csv in member.name:\n",
    "                file_obj = tar.extractfile(member)\n",
    "                if file_obj:\n",
    "                    # Wrap as text and read a fixed chunk\n",
    "                    text_stream = io.TextIOWrapper(file_obj, encoding=\"utf-8\", newline='')\n",
    "                    start = time.time()\n",
    "                    sample = text_stream.read(sample_bytes)  # read by characters (not lines)\n",
    "                    elapsed = time.time() - start\n",
    "\n",
    "                    num_lines = sample.count('\\n')\n",
    "                    avg_line_length = len(sample) / max(num_lines, 1)\n",
    "                    estimated_total_lines = int(member.size / avg_line_length)\n",
    "\n",
    "                    print(f\"Sampled {sample_bytes} bytes in {elapsed:.2f} sec\")\n",
    "                    print(f\"Estimated average line length: {avg_line_length:.1f} bytes\")\n",
    "                    print(f\"Estimated total lines: {estimated_total_lines:,}\")\n",
    "                    return estimated_total_lines\n",
    "    return 0\n",
    "\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "def default_inner():\n",
    "    return [0, 0.0, 0.0]\n",
    "\n",
    "def default_outer():\n",
    "    return defaultdict(default_inner)\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    local_clusters = defaultdict(default_outer)\n",
    "\n",
    "    chunk = chunk.dropna(subset=[\"latitude\", \"longitude\", \"taxon_id\", \"observed_on\"])\n",
    "    chunk[\"year\"] = pd.to_datetime(chunk[\"observed_on\"], errors=\"coerce\").dt.year\n",
    "    chunk = chunk.dropna(subset=[\"year\"])\n",
    "    chunk[\"year\"] = chunk[\"year\"].astype(int)\n",
    "    chunk = chunk[chunk[\"taxon_id\"].astype(int).astype(str).isin(valid_taxon_ids)]\n",
    "\n",
    "    for _, row in chunk.iterrows():\n",
    "        taxon = str(row[\"taxon_id\"])\n",
    "        year = int(row[\"year\"])\n",
    "        lat, lon = row[\"latitude\"], row[\"longitude\"]\n",
    "        grid = get_grid_key(lat, lon)\n",
    "        g = local_clusters[(taxon, year)][grid]\n",
    "        g[0] += 1\n",
    "        g[1] += lat\n",
    "        g[2] += lon\n",
    "\n",
    "    return local_clusters\n",
    "\n",
    "def merge_clusters(global_clusters, local_clusters):\n",
    "    for key, grid_dict in local_clusters.items():\n",
    "        for grid, values in grid_dict.items():\n",
    "            g = global_clusters[key][grid]\n",
    "            g[0] += values[0]\n",
    "            g[1] += values[1]\n",
    "            g[2] += values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9c76e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Taxa:  26%|███████████████████████████████████████▌                                                                                                                   | 3759/14717 [02:11<01:43, 105.74it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  28%|███████████████████████████████████████████▉                                                                                                               | 4171/14717 [02:18<01:07, 155.13it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  43%|███████████████████████████████████████████████████████████████████▎                                                                                       | 6391/14717 [02:51<01:19, 104.49it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  44%|████████████████████████████████████████████████████████████████████▌                                                                                      | 6515/14717 [02:52<01:01, 133.84it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  45%|██████████████████████████████████████████████████████████████████████▏                                                                                    | 6670/14717 [02:53<00:43, 184.40it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  46%|██████████████████████████████████████████████████████████████████████▋                                                                                    | 6709/14717 [02:53<00:45, 175.75it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  55%|██████████████████████████████████████████████████████████████████████████████████████                                                                      | 8115/14717 [03:18<03:06, 35.31it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  55%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 8152/14717 [03:19<04:11, 26.07it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  57%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 8345/14717 [03:20<00:39, 161.92it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  57%|████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 8385/14717 [03:21<00:40, 158.09it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  59%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 8701/14717 [03:23<00:48, 124.53it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  61%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                                             | 8926/14717 [03:30<06:11, 15.61it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  64%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 9419/14717 [03:35<00:34, 155.35it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  64%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 9487/14717 [03:37<01:34, 55.30it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  65%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 9595/14717 [03:38<00:50, 102.32it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 9653/14717 [03:38<00:33, 149.75it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 10981/14717 [04:14<01:50, 33.83it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                              | 11825/14717 [04:30<01:45, 27.49it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 12227/14717 [04:38<01:54, 21.76it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 13175/14717 [04:46<00:09, 161.55it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 13685/14717 [04:50<00:06, 160.49it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 13705/14717 [04:51<00:05, 169.83it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋          | 13727/14717 [04:51<00:05, 182.55it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊         | 13844/14717 [04:52<00:06, 128.23it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 13861/14717 [04:52<00:06, 138.13it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 13912/14717 [04:52<00:05, 143.33it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 13945/14717 [04:52<00:04, 154.43it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa:  96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌      | 14105/14717 [04:53<00:04, 132.35it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 14691/14717 [05:01<00:00, 147.12it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 14709/14717 [05:01<00:00, 153.27it/s]C:\\Users\\backe\\AppData\\Local\\Temp\\ipykernel_25636\\1374677885.py:51: RuntimeWarning: Mean of empty slice\n",
      "  avg2 = np.nanmean([pop2023, pop2024])\n",
      "Processing Taxa: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14717/14717 [05:01<00:00, 48.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from itertools import combinations\n",
    "from geopy.distance import geodesic\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load filtered_df\n",
    "filtered_df = pd.read_csv(\"taxon_grid_clusters_by_year.csv\")\n",
    "\n",
    "# Group to get yearly total population (sum of cluster_count)\n",
    "grouped = (\n",
    "    filtered_df.groupby([\"taxon_id\", \"year\"])[\"cluster_count\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"cluster_count\": \"population\"})\n",
    ")\n",
    "\n",
    "features = []\n",
    "\n",
    "# Add tqdm progress bar to taxon_id loop\n",
    "for taxon_id, taxon_df in tqdm(grouped.groupby(\"taxon_id\"), desc=\"Processing Taxa\"):\n",
    "    \n",
    "    taxon_df = taxon_df.sort_values(\"year\")\n",
    "    min_year = taxon_df[\"year\"].min()\n",
    "    max_year = taxon_df[\"year\"].max()\n",
    "\n",
    "    # Full year range including forecast up to 2024\n",
    "    full_years = np.arange(min_year, 2025)\n",
    "    full_df = pd.DataFrame({\"year\": full_years})\n",
    "    full_df[\"taxon_id\"] = taxon_id\n",
    "    full_df = full_df.merge(taxon_df, on=[\"taxon_id\", \"year\"], how=\"left\")\n",
    "    full_df[\"population\"] = full_df[\"population\"].interpolate(method=\"linear\")\n",
    "\n",
    "    # PCHIP extrapolation if needed\n",
    "    if max_year < 2025 and len(taxon_df) >= 2:\n",
    "        pchip = PchipInterpolator(\n",
    "            taxon_df[\"year\"], taxon_df[\"population\"]\n",
    "        )\n",
    "        extrap_years = full_df[(full_df[\"year\"] > max_year) & (full_df[\"year\"] <= 2024)][\"year\"]\n",
    "        if not extrap_years.empty:\n",
    "            full_df.loc[full_df[\"year\"].isin(extrap_years), \"population\"] = pchip(extrap_years)\n",
    "\n",
    "\n",
    "    # Final smoothed population series\n",
    "    pop_series = full_df.set_index(\"year\")[\"population\"]\n",
    "\n",
    "    # Rolling window features\n",
    "    pop2024 = pop_series.get(2024, np.nan)\n",
    "    pop2023 = pop_series.get(2023, np.nan)\n",
    "    avg2 = np.nanmean([pop2023, pop2024])\n",
    "\n",
    "    avg5 = pop_series.loc[2020:2024].mean() if all(y in pop_series for y in range(2020, 2024)) else np.nan\n",
    "    avg10 = pop_series.loc[2015:2024].mean() if all(y in pop_series for y in range(2015, 2024)) else np.nan\n",
    "\n",
    "    # Get 2025 cluster info\n",
    "    curr_clusters_df = filtered_df[\n",
    "        (filtered_df[\"taxon_id\"] == taxon_id) & (filtered_df[\"year\"] == 2024)\n",
    "    ]\n",
    "\n",
    "    curr_clusters = curr_clusters_df.shape[0]\n",
    "\n",
    "    coords = list(zip(curr_clusters_df[\"centroid_lat\"], curr_clusters_df[\"centroid_lon\"]))\n",
    "\n",
    "    if len(coords) >= 2:\n",
    "        distances = [geodesic(p1, p2).km for p1, p2 in combinations(coords, 2)]\n",
    "        avg_dist_clusters = np.mean(distances)\n",
    "        max_dist_clusters = np.max(distances)\n",
    "    else:\n",
    "        avg_dist_clusters = 0.0\n",
    "        max_dist_clusters = 0.0\n",
    "\n",
    "    features.append({\n",
    "        \"taxon_id\": taxon_id,\n",
    "        \"curr_pop\": pop2024,\n",
    "        \"avg2\": avg2,\n",
    "        \"avg5\": avg5,\n",
    "        \"avg10\": avg10,\n",
    "        \"curr_clusters\": curr_clusters,\n",
    "        \"avg_dist_clusters\": avg_dist_clusters,\n",
    "        \"max_dist_clusters\": max_dist_clusters\n",
    "    })\n",
    "\n",
    "# Combine to final DataFrame\n",
    "regression_features_df = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04239f3f",
   "metadata": {},
   "source": [
    "Prepare Regression Data for Conservation Status Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c2aca39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['taxon_id', 'curr_pop', 'avg2', 'avg5', 'avg10', 'curr_clusters',\n",
      "       'avg_dist_clusters', 'max_dist_clusters', 'ancestry', 'rank_level',\n",
      "       'rank', 'name', 'active', 'conservation_status'],\n",
      "      dtype='object')\n",
      "       curr_pop      avg2      avg5     avg10  curr_clusters  \\\n",
      "0      0.992508  1.259202  1.146376  1.245539       2.233065   \n",
      "1     -0.002665 -0.003246 -0.025871 -0.020163       0.834223   \n",
      "2     -0.167331 -0.161052 -0.158858 -0.160677      -0.253766   \n",
      "3     -0.070638 -0.074647 -0.088791 -0.077140       1.611357   \n",
      "4     -0.153928 -0.157689 -0.153880 -0.153181      -0.098339   \n",
      "...         ...       ...       ...       ...            ...   \n",
      "14712 -0.173075 -0.173987 -0.167919 -0.171173      -0.486907   \n",
      "14713 -0.169964 -0.171271 -0.165558 -0.167585      -0.486907   \n",
      "14714 -0.171160 -0.172694 -0.165622 -0.167318      -0.409193   \n",
      "14715 -0.172596 -0.173211 -0.166771 -0.168389      -0.409193   \n",
      "14716 -0.173075 -0.173987 -0.167919 -0.171173      -0.409193   \n",
      "\n",
      "       avg_dist_clusters  max_dist_clusters  ancestry  conservation_status  \n",
      "0               1.276396           1.575409         1                    0  \n",
      "1               1.860025           1.835466         1                    0  \n",
      "2              -0.386954          -0.449204         1                    0  \n",
      "3               1.532172           1.570500         1                    0  \n",
      "4               1.885956           1.907725         1                    1  \n",
      "...                  ...                ...       ...                  ...  \n",
      "14712          -0.682066          -0.625861         0                    0  \n",
      "14713          -0.682066          -0.625861         0                    0  \n",
      "14714          -0.682066          -0.625861         0                    0  \n",
      "14715          -0.682066          -0.625861         0                    0  \n",
      "14716          -0.682066          -0.625861         0                    0  \n",
      "\n",
      "[14717 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(regression_features_df)\n",
    "conservation_df = pd.read_csv('backend/data/filtered_species_with_conservation_status.csv')\n",
    "new_df = regression_features_df.merge(conservation_df, on='taxon_id', how='left')\n",
    "print(new_df.columns)\n",
    "new_df = new_df[[\n",
    "    'curr_pop','avg2', 'avg5', 'avg10', 'curr_clusters',\n",
    "    'avg_dist_clusters', 'max_dist_clusters',\n",
    "    'ancestry', 'conservation_status'\n",
    "]]\n",
    "\n",
    "#if conservation status == 'threatened', conservation_status=1, else 0\n",
    "new_df[\"conservation_status\"] = (new_df[\"conservation_status\"] == \"threatened\").astype(int)\n",
    "\n",
    "#remove some NaNs\n",
    "new_df[\"curr_pop\"] = new_df[\"curr_pop\"].fillna(0)\n",
    "new_df[\"avg2\"] = new_df[\"avg2\"].fillna(new_df[\"curr_pop\"])\n",
    "new_df[\"avg5\"] = new_df[\"avg5\"].fillna(new_df[\"avg2\"])\n",
    "new_df[\"avg10\"] = new_df[\"avg10\"].fillna(new_df[\"avg5\"])\n",
    "\n",
    "#reduce ancestry to only the 2 groups\n",
    "target_classes = [\"40151\", \"3\"]\n",
    "\n",
    "def extract_target_class(ancestry):\n",
    "    parts = ancestry.split('/')\n",
    "    for tid in target_classes:\n",
    "        if tid in parts:\n",
    "            return 1 if tid == \"3\" else 0\n",
    "    return ancestry  # Or return \"other\" / None if you want to drop non-targets\n",
    "\n",
    "# Apply transformation\n",
    "new_df[\"ancestry\"] = new_df[\"ancestry\"].astype(str).apply(extract_target_class)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numeric columns to normalize\n",
    "num_cols = ['curr_pop','avg2', 'avg5', 'avg10', 'curr_clusters', 'avg_dist_clusters', 'max_dist_clusters']\n",
    "scaler = StandardScaler()\n",
    "new_df[num_cols] = scaler.fit_transform(new_df[num_cols])\n",
    "\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af42b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy: 0.6222826086956522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.74      2273\n",
      "           1       0.27      0.39      0.32       671\n",
      "\n",
      "    accuracy                           0.62      2944\n",
      "   macro avg       0.53      0.54      0.53      2944\n",
      "weighted avg       0.67      0.62      0.64      2944\n",
      "\n",
      "=== Naive Bayes ===\n",
      "Accuracy: 0.27683423913043476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.07      0.13      2273\n",
      "           1       0.24      0.97      0.38       671\n",
      "\n",
      "    accuracy                           0.28      2944\n",
      "   macro avg       0.57      0.52      0.26      2944\n",
      "weighted avg       0.75      0.28      0.19      2944\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.7102581521739131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      2273\n",
      "           1       0.36      0.35      0.36       671\n",
      "\n",
      "    accuracy                           0.71      2944\n",
      "   macro avg       0.59      0.58      0.59      2944\n",
      "weighted avg       0.71      0.71      0.71      2944\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "Accuracy: 0.7730978260869565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87      2273\n",
      "           1       0.52      0.06      0.11       671\n",
      "\n",
      "    accuracy                           0.77      2944\n",
      "   macro avg       0.65      0.52      0.49      2944\n",
      "weighted avg       0.72      0.77      0.70      2944\n",
      "\n",
      "=== Support Vector Machine ===\n",
      "Accuracy: 0.5784646739130435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.52      0.66      2273\n",
      "           1       0.32      0.78      0.46       671\n",
      "\n",
      "    accuracy                           0.58      2944\n",
      "   macro avg       0.61      0.65      0.56      2944\n",
      "weighted avg       0.76      0.58      0.61      2944\n",
      "\n",
      "=== K-Nearest Neighbors ===\n",
      "Accuracy: 0.7306385869565217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83      2273\n",
      "           1       0.36      0.23      0.28       671\n",
      "\n",
      "    accuracy                           0.73      2944\n",
      "   macro avg       0.58      0.56      0.56      2944\n",
      "weighted avg       0.70      0.73      0.71      2944\n",
      "\n",
      "=== Decision Tree ===\n",
      "Accuracy: 0.6491168478260869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76      2273\n",
      "           1       0.32      0.47      0.38       671\n",
      "\n",
      "    accuracy                           0.65      2944\n",
      "   macro avg       0.57      0.59      0.57      2944\n",
      "weighted avg       0.70      0.65      0.67      2944\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy: 0.639266304347826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.63      0.73      2273\n",
      "           1       0.35      0.66      0.45       671\n",
      "\n",
      "    accuracy                           0.64      2944\n",
      "   macro avg       0.60      0.65      0.59      2944\n",
      "weighted avg       0.74      0.64      0.67      2944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\backe\\Documents\\GitHub\\species_tracker\\.venv\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:39:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Features and labels\n",
    "reg_features = ['ancestry', 'curr_pop', 'avg2', 'avg5', 'avg10',\n",
    "                'curr_clusters', 'avg_dist_clusters', 'max_dist_clusters']\n",
    "X_reg = new_df[reg_features]\n",
    "y = new_df['conservation_status']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reg, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"XGBoost\" : XGBClassifier(scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(), use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae7e82",
   "metadata": {},
   "source": [
    "We have determined SVM is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d1b91ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for SVM: 0.28 | F1-score: 0.4662\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# Get predicted probabilities for class 1\n",
    "svm_probs = models[\"Support Vector Machine\"].predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Try different thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 50)\n",
    "f1_scores = []\n",
    "best_thresh = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (svm_probs >= thresh).astype(int)\n",
    "    score = f1_score(y_test, y_pred_thresh)\n",
    "    f1_scores.append(score)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_thresh = thresh\n",
    "\n",
    "print(f\"Best threshold for SVM: {best_thresh:.2f} | F1-score: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ae617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       true_label  predicted  confidence\n",
      "10275           1          1    0.619120\n",
      "10643           0          1    0.651268\n",
      "9490            0          1    0.651603\n",
      "13025           0          0    0.802738\n",
      "11459           1          1    0.651488\n",
      "...           ...        ...         ...\n",
      "6598            1          1    0.651560\n",
      "14632           0          1    0.651268\n",
      "13104           0          1    0.651805\n",
      "3844            0          0    0.885960\n",
      "14283           0          1    0.651920\n",
      "\n",
      "[2944 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "probs = models[\"Support Vector Machine\"].predict_proba(X_test)\n",
    "y_pred = (probs[:, 1] >= 0.28).astype(int)        # your custom threshold\n",
    "confidences = probs.max(axis=1)                 # confidence = max probability\n",
    "decision_scores = models[\"Support Vector Machine\"].decision_function(X_test)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"true_label\": y_test,\n",
    "    \"predicted\": y_pred,\n",
    "    \"confidence\": confidences\n",
    "})\n",
    "\n",
    "#print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f920dacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ancestry', 'curr_pop', 'avg2', 'avg5', 'avg10', 'curr_clusters', 'avg_dist_clusters', 'max_dist_clusters']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_model_bundle.joblib']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Bundle everything you need\n",
    "print(reg_features)\n",
    "bundle = {\n",
    "    \"model\": models[\"Support Vector Machine\"],\n",
    "    \"scaler\": scaler,\n",
    "    \"threshold\": 0.28,\n",
    "    \"features\": reg_features  # optional but useful\n",
    "}\n",
    "\n",
    "# Save it as one .joblib file\n",
    "joblib.dump(bundle, \"svm_model_bundle.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
